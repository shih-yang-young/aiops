{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02b729c4-2591-47dc-9212-071e05b41d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Inbound Message</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>login issue verified user details employee man...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>outlook hello team meetings skype meetings etc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cant log vpn cannot log vpn best</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unable access tool page unable access tool page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>skype error skype error</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8449</th>\n",
       "      <td>emails coming mail good afternoon receiving em...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8450</th>\n",
       "      <td>telephony software issue telephony software issue</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8451</th>\n",
       "      <td>vip windows password reset tifpdchb pedxruyf v...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8452</th>\n",
       "      <td>machine est funcionando unable access machine ...</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8453</th>\n",
       "      <td>mehreren lassen sich verschiedene prgramdntyme...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8454 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Inbound Message  Label\n",
       "0     login issue verified user details employee man...      0\n",
       "1     outlook hello team meetings skype meetings etc...      0\n",
       "2                      cant log vpn cannot log vpn best      0\n",
       "3       unable access tool page unable access tool page      0\n",
       "4                               skype error skype error      0\n",
       "...                                                 ...    ...\n",
       "8449  emails coming mail good afternoon receiving em...     22\n",
       "8450  telephony software issue telephony software issue      0\n",
       "8451  vip windows password reset tifpdchb pedxruyf v...      0\n",
       "8452  machine est funcionando unable access machine ...     44\n",
       "8453  mehreren lassen sich verschiedene prgramdntyme...     49\n",
       "\n",
       "[8454 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_path = \"../../data/open_source_8454_combine_short_description.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "# df_label_0 = df[df[\"Label\"] == 0]\n",
    "# df_label_0_to_drop = df_label_0.sample(n=3000, random_state=42)\n",
    "# df = df.drop(df_label_0_to_drop.index)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87a40d82-939e-4929-acf7-176e15f86f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../ml_lib'))\n",
    "\n",
    "from config import *\n",
    "from dataset import CustomDataset\n",
    "from train_eval import train_epoch, eval_model\n",
    "from device import get_device_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19e57422-f61c-4c60-b96b-868d0935030f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "CUDA Available: True\n",
      "CUDA Device: NVIDIA GeForce RTX 3050 6GB Laptop GPU\n",
      "Current GPU Memory Allocated: 0.00 GB\n",
      "Current GPU Memory Cached: 0.00 GB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "device = get_device_info()\n",
    "messages, labels = df['Inbound Message'].tolist(), df['Label'].tolist()\n",
    "\n",
    "# KFold 初始化\n",
    "skf = StratifiedKFold(n_splits=KFOLD_SPLIT, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bedda39-23eb-477a-92af-5bb663edac12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, RobertaTokenizer, DebertaTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "def get_tokenizer(model_name):\n",
    "    if \"bert\" in model_name.lower():\n",
    "        return BertTokenizer.from_pretrained(model_name)\n",
    "    elif \"roberta\" in model_name.lower():\n",
    "        return RobertaTokenizer.from_pretrained(model_name)\n",
    "    elif \"deberta\" in model_name.lower():\n",
    "        return DebertaTokenizer.from_pretrained(model_name)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model tokenizer.\")\n",
    "\n",
    "def get_model(model_name, hybrid=None, num_labels=2):\n",
    "    if hybrid is None:\n",
    "        return AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "    elif hybrid == \"lstm\":\n",
    "        return BertLSTMClassifier(model_name, num_labels)\n",
    "    elif hybrid == \"bilstm\":\n",
    "        return BertBiLSTMClassifier(model_name, num_labels)\n",
    "    elif hybrid == \"cnn\":\n",
    "        return BertCNNClassifier(model_name, num_labels)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported hybrid type.\")\n",
    "\n",
    "def apply_resampling(X, y, method=\"none\"):\n",
    "    if method == \"none\":\n",
    "        return X, y\n",
    "    elif method == \"ros\":\n",
    "        return RandomOverSampler().fit_resample(X, y)\n",
    "    elif method == \"smote\":\n",
    "        return SMOTE().fit_resample(X, y)\n",
    "    elif method == \"textgan\":\n",
    "        return textgan_augment(X, y)  # 假設你有自訂 function\n",
    "    else:\n",
    "        raise ValueError(\"Unknown resampling method\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a86418c9-592f-4591-92f6-3f42920bc2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import AdamW\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def run_kfold_experiment(\n",
    "    X, y, model_name, hybrid_type, resample_method, tokenizer,\n",
    "    kfold=KFOLD_SPLIT, patience=PATIENCE, max_length=MAX_LENGTH, \n",
    "    batch_size=BATCH_SIZE, lr=LR, weight_decay=WEIGHT_DECAY\n",
    "):\n",
    "    skf = StratifiedKFold(n_splits=kfold, shuffle=True, random_state=SEED)\n",
    "    all_fold_results = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        print(f\"\\n[Fold {fold + 1}]\")\n",
    "        X_train = [X[i] for i in train_idx]\n",
    "        y_train = [y[i] for i in train_idx]\n",
    "        X_val = [X[i] for i in val_idx]\n",
    "        y_val = [y[i] for i in val_idx]\n",
    "\n",
    "        X_train, y_train = apply_resampling(X_train, y_train, method=resample_method)\n",
    "\n",
    "        train_dataset = CustomDataset(X_train, y_train, tokenizer, max_length)\n",
    "        val_dataset = CustomDataset(X_val, y_val, tokenizer, max_length)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "        num_labels = len(set(y))\n",
    "        model = get_model(model_name, hybrid_type, num_labels=num_labels)\n",
    "        model.to(device)\n",
    "\n",
    "        optimizer = AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        criterion = CrossEntropyLoss()\n",
    "\n",
    "        epoch_results = []\n",
    "        best_macro_f1 = 0\n",
    "        epochs_without_improvement = 0\n",
    "\n",
    "        for epoch in range(EPOCHS):\n",
    "            print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
    "            train_loss = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "            metrics = eval_model(model, val_loader, criterion, device, num_labels)\n",
    "            print(metrics)\n",
    "            epoch_results.append(metrics)\n",
    "\n",
    "            current_macro_f1 = metrics[\"macro_f1-score\"]\n",
    "            if current_macro_f1 > best_macro_f1:\n",
    "                best_macro_f1 = current_macro_f1\n",
    "                epochs_without_improvement = 0\n",
    "            else:\n",
    "                epochs_without_improvement += 1\n",
    "\n",
    "            if epochs_without_improvement >= patience:\n",
    "                print(\"Early stopping.\")\n",
    "                break\n",
    "\n",
    "        best_epoch_metrics = max(epoch_results, key=lambda x: x[\"macro_f1-score\"])\n",
    "        all_fold_results.append(best_epoch_metrics)\n",
    "\n",
    "    return all_fold_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd6b9b00-8ce0-435a-b709-95bd774f5342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ Running: bert-base-uncased + plain + none\n",
      "\n",
      "[Fold 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\cuda\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [03:30<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': 1.5768805764756113, 'val_accuracy': 0.6205673758865248, 'precision': 0.4982209971912229, 'recall': 0.6205673758865248, 'f1-score': 0.50601774679372, 'macro_f1-score': 0.10698931571681669, 'balanced_accuracy': 0.11806378673375514, 'mcc': 0.4543086361958166}\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 25/476 [00:11<03:23,  2.22it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m resample \u001b[38;5;129;01min\u001b[39;00m resample_list:\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m▶ Running: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m + \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhybrid\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplain\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m + \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresample\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m     results \u001b[38;5;241m=\u001b[39m run_kfold_experiment(\n\u001b[0;32m     11\u001b[0m         messages, labels, model_name, hybrid, resample, tokenizer\n\u001b[0;32m     12\u001b[0m     )\n",
      "Cell \u001b[1;32mIn[5], line 42\u001b[0m, in \u001b[0;36mrun_kfold_experiment\u001b[1;34m(X, y, model_name, hybrid_type, resample_method, tokenizer, kfold, patience, max_length, batch_size, lr, weight_decay)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 42\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m train_epoch(model, train_loader, optimizer, criterion, device)\n\u001b[0;32m     43\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m eval_model(model, val_loader, criterion, device, num_labels)\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28mprint\u001b[39m(metrics)\n",
      "File \u001b[1;32m~\\Jupyter\\aiops\\src\\ml_lib\\train_eval.py:12\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(model, dataloader, optimizer, criterion, device)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(dataloader):\n\u001b[0;32m     11\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 12\u001b[0m     input_ids \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     13\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     14\u001b[0m     labels \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_list = [\"bert-base-uncased\", \"roberta-base\", \"microsoft/deberta-base\"]\n",
    "hybrid_list = [None, \"cnn\", \"lstm\", \"bilstm\"]\n",
    "resample_list = [\"none\", \"ros\", \"smote\", \"textgan\"]\n",
    "\n",
    "for model_name in model_list:\n",
    "    tokenizer = get_tokenizer(model_name)\n",
    "    for hybrid in hybrid_list:\n",
    "        for resample in resample_list:\n",
    "            print(f\"▶ Running: {model_name} + {hybrid or 'plain'} + {resample}\")\n",
    "            results = run_kfold_experiment(\n",
    "                messages, labels, model_name, hybrid, resample, tokenizer\n",
    "            )\n",
    "            # 儲存 results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b2f834-4634-46b9-ab82-6b1e031ea867",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50cc73e-1ab9-41bc-85d5-96c52042ba35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
