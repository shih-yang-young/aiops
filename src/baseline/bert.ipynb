{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02b729c4-2591-47dc-9212-071e05b41d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Inbound Message</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>outlook hello team meetings skype meetings etc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>skype error skype error</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>event critical hostname company com value moun...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>engineering tool says connected unable submit ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>unable login tool sgxqsuojr xwbesorf cards una...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8447</th>\n",
       "      <td>erp two accounts added sorry another two accou...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8448</th>\n",
       "      <td>tablet needs reimaged due multiple issues crm ...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8449</th>\n",
       "      <td>emails coming mail good afternoon receiving em...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8452</th>\n",
       "      <td>machine est funcionando unable access machine ...</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8453</th>\n",
       "      <td>mehreren lassen sich verschiedene prgramdntyme...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5454 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Inbound Message  Label\n",
       "1     outlook hello team meetings skype meetings etc...      0\n",
       "4                               skype error skype error      0\n",
       "6     event critical hostname company com value moun...      1\n",
       "10    engineering tool says connected unable submit ...      0\n",
       "12    unable login tool sgxqsuojr xwbesorf cards una...      0\n",
       "...                                                 ...    ...\n",
       "8447  erp two accounts added sorry another two accou...      2\n",
       "8448  tablet needs reimaged due multiple issues crm ...     23\n",
       "8449  emails coming mail good afternoon receiving em...     22\n",
       "8452  machine est funcionando unable access machine ...     44\n",
       "8453  mehreren lassen sich verschiedene prgramdntyme...     49\n",
       "\n",
       "[5454 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_path = \"../../data/open_source_8454_combine_short_description.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "# df_label_0 = df[df[\"Label\"] == 0]\n",
    "# df_label_0_to_drop = df_label_0.sample(n=3000, random_state=42)\n",
    "# df = df.drop(df_label_0_to_drop.index)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87a40d82-939e-4929-acf7-176e15f86f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../ml_lib'))\n",
    "\n",
    "from config import *\n",
    "from dataset import CustomDataset\n",
    "from train_eval import train_epoch, eval_model\n",
    "from device import get_device_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19e57422-f61c-4c60-b96b-868d0935030f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "CUDA Available: True\n",
      "CUDA Device: NVIDIA GeForce RTX 3050 6GB Laptop GPU\n",
      "Current GPU Memory Allocated: 0.00 GB\n",
      "Current GPU Memory Cached: 0.00 GB\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "device = get_device_info()\n",
    "\n",
    "messages, labels = df['Inbound Message'].tolist(), df['Label'].tolist()\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# KFold 初始化\n",
    "skf = StratifiedKFold(n_splits=KFOLD_SPLIT, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83de0792-25a1-4362-b343-f267dd79b3ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\cuda\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 7 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Training set label distribution: {0: 876, 1: 28, 2: 126, 3: 27, 4: 231, 5: 130, 6: 107, 7: 35, 8: 76, 9: 73, 10: 79, 11: 194, 12: 217, 13: 32, 14: 26, 15: 28, 16: 23, 17: 260, 18: 104, 19: 51, 20: 16, 21: 39, 22: 88, 23: 180, 24: 18, 25: 56, 26: 97, 27: 55, 28: 13, 29: 15, 30: 17, 31: 90, 32: 40, 33: 36, 34: 34, 35: 13, 36: 32, 37: 24, 38: 7, 39: 116, 40: 13, 41: 9, 42: 166, 43: 18, 44: 22, 45: 10, 46: 61, 47: 595, 48: 227, 49: 78}\n",
      "Validation set label distribution: {0: 98, 1: 3, 2: 14, 3: 3, 4: 26, 5: 15, 6: 11, 7: 4, 8: 9, 9: 8, 10: 9, 11: 21, 12: 24, 13: 4, 14: 3, 15: 3, 16: 2, 17: 29, 18: 12, 19: 5, 20: 2, 21: 5, 22: 9, 23: 20, 24: 2, 25: 7, 26: 10, 27: 6, 28: 2, 29: 1, 30: 2, 31: 10, 32: 5, 33: 4, 34: 3, 35: 2, 36: 3, 37: 3, 39: 13, 40: 1, 41: 2, 42: 18, 43: 2, 44: 3, 45: 1, 46: 7, 47: 66, 48: 25, 49: 9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307/307 [02:10<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': 2.1378087520599367, 'val_accuracy': 0.41208791208791207, 'precision': 0.28925255435049985, 'recall': 0.41208791208791207, 'f1-score': 0.29951824907403585, 'macro_f1-score': 0.10259991974422954, 'balanced_accuracy': 0.12564264092865682, 'mcc': 0.3563669747549857}\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 79/307 [00:33<01:37,  2.35it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 39\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 39\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m train_epoch(model, train_dataloader, optimizer, criterion, device)\n\u001b[0;32m     40\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m eval_model(model, val_dataloader, criterion, device, num_labels\u001b[38;5;241m=\u001b[39mNUM_LABELS)\n\u001b[0;32m     41\u001b[0m     epoch_results\u001b[38;5;241m.\u001b[39mappend(metrics)\n",
      "File \u001b[1;32m~\\Jupyter\\aiops\\src\\ml_lib\\train_eval.py:12\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(model, dataloader, optimizer, criterion, device)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(dataloader):\n\u001b[0;32m     11\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 12\u001b[0m     input_ids \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     13\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     14\u001b[0m     labels \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import AdamW\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "all_fold_results = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(messages, labels)):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "    \n",
    "    train_messages = [messages[i] for i in train_idx]\n",
    "    train_labels = [labels[i] for i in train_idx]\n",
    "    val_messages = [messages[i] for i in val_idx]\n",
    "    val_labels = [labels[i] for i in val_idx]\n",
    "\n",
    "    print(\"Training set label distribution:\", {label: train_labels.count(label) for label in set(train_labels)})\n",
    "    print(\"Validation set label distribution:\", {label: val_labels.count(label) for label in set(val_labels)})\n",
    "    \n",
    "    train_dataset = CustomDataset(train_messages, train_labels, tokenizer, MAX_LENGTH)\n",
    "    val_dataset = CustomDataset(val_messages, val_labels, tokenizer, MAX_LENGTH)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "    NUM_LABELS = len(set(train_labels) | set(val_labels))\n",
    "    model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=NUM_LABELS)\n",
    "    model.to(device)\n",
    "    optimizer = AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    epoch_results = []\n",
    "    best_macro_f1 = 0\n",
    "    epochs_without_improvement = 0\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
    "        train_loss = train_epoch(model, train_dataloader, optimizer, criterion, device)\n",
    "        metrics = eval_model(model, val_dataloader, criterion, device, num_labels=NUM_LABELS)\n",
    "        epoch_results.append(metrics)\n",
    "        print(metrics)\n",
    "\n",
    "        current_macro_f1 = metrics[\"macro_f1-score\"]\n",
    "        \n",
    "        if current_macro_f1 > best_macro_f1:\n",
    "            best_macro_f1 = current_macro_f1  # 更新最佳 macro_f1-score\n",
    "            epochs_without_improvement = 0   # 重置計數\n",
    "        else:\n",
    "            epochs_without_improvement += 1  # 增加計數\n",
    "        \n",
    "        # 若連續 patience 3 次沒有提升，則停止訓練\n",
    "        if epochs_without_improvement >= PATIENCE:\n",
    "            print(f\"Early stopping triggered at epoch {epoch + 1}\")\n",
    "            break\n",
    "    \n",
    "    # avg_metrics = {metric: np.mean([epoch[metric] for epoch in epoch_results]) for metric in epoch_results[0].keys()}\n",
    "    # all_fold_results.append(avg_metrics)\n",
    "    best_epoch_metrics = max(epoch_results, key=lambda x: x[\"macro_f1-score\"])\n",
    "    all_fold_results.append(best_epoch_metrics)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Total time: {end_time - start_time:.2f}s\")\n",
    "\n",
    "final_metrics = {metric: np.mean([result[metric] for result in all_fold_results]) for metric in all_fold_results[0].keys()}\n",
    "print(\"Final 10-fold Cross-Validation Results:\")\n",
    "for metric, value in final_metrics.items():\n",
    "    print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41b2f834-4634-46b9-ab82-6b1e031ea867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 2.1378087520599367,\n",
       "  'val_accuracy': 0.41208791208791207,\n",
       "  'precision': 0.28925255435049985,\n",
       "  'recall': 0.41208791208791207,\n",
       "  'f1-score': 0.29951824907403585,\n",
       "  'macro_f1-score': 0.10259991974422954,\n",
       "  'balanced_accuracy': 0.12564264092865682,\n",
       "  'mcc': 0.3563669747549857}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50cc73e-1ab9-41bc-85d5-96c52042ba35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
