{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e76aa66-729a-4bf9-98b9-61d8114e9f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Inbound Message</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>login issue verified user details employee man...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>outlook hello team meetings skype meetings etc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cant log vpn cannot log vpn best</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unable access tool page unable access tool page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>skype error skype error</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8449</th>\n",
       "      <td>emails coming mail good afternoon receiving em...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8450</th>\n",
       "      <td>telephony software issue telephony software issue</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8451</th>\n",
       "      <td>vip windows password reset tifpdchb pedxruyf v...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8452</th>\n",
       "      <td>machine est funcionando unable access machine ...</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8453</th>\n",
       "      <td>mehreren lassen sich verschiedene prgramdntyme...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8454 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Inbound Message  Label\n",
       "0     login issue verified user details employee man...      0\n",
       "1     outlook hello team meetings skype meetings etc...      0\n",
       "2                      cant log vpn cannot log vpn best      0\n",
       "3       unable access tool page unable access tool page      0\n",
       "4                               skype error skype error      0\n",
       "...                                                 ...    ...\n",
       "8449  emails coming mail good afternoon receiving em...     22\n",
       "8450  telephony software issue telephony software issue      0\n",
       "8451  vip windows password reset tifpdchb pedxruyf v...      0\n",
       "8452  machine est funcionando unable access machine ...     44\n",
       "8453  mehreren lassen sich verschiedene prgramdntyme...     49\n",
       "\n",
       "[8454 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_path = \"../data/open_source_8454_combine_short_description.csv\"  # 替換為你的檔案路徑\n",
    "df = pd.read_csv(data_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79be804-d1e3-463a-824f-d4765544e493",
   "metadata": {},
   "source": [
    "# 十折驗證法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e6a5029-3898-4bab-8d6c-bfd1a3694153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "CUDA Available: True\n",
      "CUDA Device: NVIDIA GeForce RTX 3050 6GB Laptop GPU\n",
      "Current GPU Memory Allocated: 0.0 GB\n",
      "Current GPU Memory Cached: 0.0 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f\"Using device: {device}\") \n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA Device: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"Current GPU Memory Allocated: {torch.cuda.memory_allocated() / 1e9} GB\")\n",
    "print(f\"Current GPU Memory Cached: {torch.cuda.memory_reserved() / 1e9} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0217a72c-db4d-4875-8a00-33f2dae9de5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "from sklearn.model_selection import KFold\n",
    "# 設定參數\n",
    "MAX_LENGTH = 128\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 20\n",
    "NUM_LABELS = len(set(labels))\n",
    "\n",
    "# 初始化 BERT 的 tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# 初始化數據\n",
    "messages = df['Inbound Message'].tolist()\n",
    "labels = df['Label'].tolist()\n",
    "\n",
    "# KFold 初始化\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "833a0227-7775-4659-a98c-48c3fbdc9db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, messages, labels, tokenizer, max_length):\n",
    "        self.messages = messages\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.messages)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        message = str(self.messages[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            message,\n",
    "            max_length=self.max_length,\n",
    "            add_special_tokens=True,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1b7047b-db5c-4a81-be16-263958db61fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "# 定義 BERT + CNN 模型\n",
    "class BERT_CNN(nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super(BERT_CNN, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.conv1 = nn.Conv1d(in_channels=768, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc = nn.Linear(256, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        x = outputs.last_hidden_state.permute(0, 2, 1)  # 調整維度以適應 CNN\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = torch.max(x, dim=2)[0]  # 最大池化\n",
    "        out = self.fc(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "985bf187-a1b5-4882-9e52-2cbc0188e8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義訓練與評估函數\n",
    "def train_epoch(model, dataloader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dceb8a1-edf1-42fe-ac48-dc84ed4709cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "    \n",
    "    accuracy = correct_predictions.double() / len(dataloader.dataset)\n",
    "    return total_loss / len(dataloader), accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee99c1b8-2fc7-483a-8cb6-d375039c6cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [03:28<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.7589590026050055 | Val loss: 1.5099717142446987 | Val accuracy: 0.5921985815602837\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [03:26<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.1777987394387983 | Val loss: 1.3251605776121032 | Val accuracy: 0.6501182033096926\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [03:26<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.8486513300415348 | Val loss: 1.2496314431136508 | Val accuracy: 0.66548463356974\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [03:27<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.6016878683057403 | Val loss: 1.286689284275163 | Val accuracy: 0.6382978723404256\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [03:26<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.4222591621683863 | Val loss: 1.411551517698 | Val accuracy: 0.6607565011820331\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [03:26<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.32998468954616983 | Val loss: 1.6226807084848296 | Val accuracy: 0.6560283687943262\n",
      "Early stopping triggered at epoch 6\n",
      "Fold 2\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 53/476 [00:23<03:29,  2.01it/s]"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# 進行 10 折交叉驗證\n",
    "fold_results = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(messages)):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "    \n",
    "    train_messages = [messages[i] for i in train_idx]\n",
    "    train_labels = [labels[i] for i in train_idx]\n",
    "    val_messages = [messages[i] for i in val_idx]\n",
    "    val_labels = [labels[i] for i in val_idx]\n",
    "    \n",
    "    train_dataset = CustomDataset(train_messages, train_labels, tokenizer, MAX_LENGTH)\n",
    "    val_dataset = CustomDataset(val_messages, val_labels, tokenizer, MAX_LENGTH)\n",
    "    \n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    model = BERT_CNN(num_labels=NUM_LABELS).to(device)\n",
    "    optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "    criterion = CrossEntropyLoss()\n",
    "    \n",
    "    patience = 3\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_without_improvement = 0\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
    "        train_loss = train_epoch(model, train_dataloader, optimizer, criterion)\n",
    "        val_loss, val_accuracy = eval_model(model, val_dataloader, criterion)\n",
    "        print(f\"Train loss: {train_loss} | Val loss: {val_loss} | Val accuracy: {val_accuracy}\")\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_without_improvement = 0\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "        \n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch + 1}\")\n",
    "            break\n",
    "    \n",
    "    fold_results.append({\"fold\": fold + 1, \"val_loss\": val_loss, \"val_accuracy\": val_accuracy.item()})\n",
    "\n",
    "# 總結 10 折結果\n",
    "avg_val_loss = np.mean([result[\"val_loss\"] for result in fold_results])\n",
    "avg_val_accuracy = np.mean([result[\"val_accuracy\"] for result in fold_results])\n",
    "print(f\"10-fold Cross-Validation Results:\")\n",
    "print(f\"Average Validation Loss: {avg_val_loss}\")\n",
    "print(f\"Average Validation Accuracy: {avg_val_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8016681-94ee-4d35-81ac-9831d7172f0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
