{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc42eafd-c536-49ec-9601-c44cc5c3dc8e",
   "metadata": {},
   "source": [
    "好的！LoRA（Low-Rank Adaptation） 是一種輕量微調（Fine-tuning）方法，特別適合 低 VRAM 設備，因為它 只調整 Transformer 的部分參數，而不微調整個模型，從而大幅降低顯存需求。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e76aa66-729a-4bf9-98b9-61d8114e9f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Inbound Message</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>verified user details employee manager name ch...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hello team meetings skype meetings etc appeari...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cannot log vpn best</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unable access tool page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>skype error</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8375</th>\n",
       "      <td>good afternoon receiving emails sent mail plea...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8376</th>\n",
       "      <td>telephony software issue</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8377</th>\n",
       "      <td>vip windows password reset tifpdchb pedxruyf</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8378</th>\n",
       "      <td>unable access machine utilities finish drawers...</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8379</th>\n",
       "      <td>mehreren lassen sich verschiedene prgramdntyme...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8380 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Inbound Message  Label\n",
       "0     verified user details employee manager name ch...      0\n",
       "1     hello team meetings skype meetings etc appeari...      0\n",
       "2                                   cannot log vpn best      0\n",
       "3                               unable access tool page      0\n",
       "4                                           skype error      0\n",
       "...                                                 ...    ...\n",
       "8375  good afternoon receiving emails sent mail plea...     22\n",
       "8376                           telephony software issue      0\n",
       "8377       vip windows password reset tifpdchb pedxruyf      0\n",
       "8378  unable access machine utilities finish drawers...     44\n",
       "8379  mehreren lassen sich verschiedene prgramdntyme...     49\n",
       "\n",
       "[8380 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_path = \"../data/open_source_8380.csv\"  # 替換為你的檔案路徑\n",
    "df = pd.read_csv(data_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e84675-64f6-4c34-8bf9-fc8accb1df25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, TrainingArguments, Trainer\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 設定 GPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# 讀取 CSV 數據\n",
    "file_path = \"/mnt/data/open_source_8380.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 定義 Few-Shot 訓練數據（每類取 5～10 筆）\n",
    "few_shot_samples = df.groupby(\"Label\").apply(lambda x: x.sample(n=min(10, len(x)))).reset_index(drop=True)\n",
    "\n",
    "# 轉換成 Hugging Face Dataset 格式\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer(text, truncation=True, padding=\"max_length\", max_length=self.max_length, return_tensors=\"pt\")\n",
    "        return {key: val.squeeze(0) for key, val in encoding.items()}, torch.tensor(label)\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# 建立訓練數據集\n",
    "train_dataset = CustomDataset(\n",
    "    texts=few_shot_samples[\"Inbound Message\"].tolist(),\n",
    "    labels=few_shot_samples[\"Label\"].tolist(),\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# LoRA 配置\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,  # 序列分類\n",
    "    r=8,  # 低秩矩陣的維度\n",
    "    lora_alpha=32,  # LoRA alpha 參數\n",
    "    lora_dropout=0.1,  # Dropout\n",
    "    target_modules=[\"query\", \"value\"]  # 只調整注意力機制的 query 和 value 層\n",
    ")\n",
    "\n",
    "# 載入 BERT 模型\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(df[\"Label\"].unique()))\n",
    "model = get_peft_model(model, lora_config)  # 加入 LoRA\n",
    "\n",
    "# 訓練參數\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=4,  # Batch size 設小，避免爆 VRAM\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=5,\n",
    "    learning_rate=3e-5,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=1,\n",
    "    report_to=\"none\"  # 不傳送到 Hugging Face Hub\n",
    ")\n",
    "\n",
    "# Trainer 物件\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset\n",
    ")\n",
    "\n",
    "# 開始訓練\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936421e9-b8a5-4ee3-94e6-ad5c097b65d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272aa559-2822-427d-991f-feaf37175345",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381caca5-aae8-4f3d-b216-4bb3bff0f6d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e79be804-d1e3-463a-824f-d4765544e493",
   "metadata": {},
   "source": [
    "# 十折驗證法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e6a5029-3898-4bab-8d6c-bfd1a3694153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "CUDA Available: True\n",
      "CUDA Device: NVIDIA GeForce RTX 3050 6GB Laptop GPU\n",
      "Current GPU Memory Allocated: 1.802484224 GB\n",
      "Current GPU Memory Cached: 3.401580544 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f\"Using device: {device}\") \n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA Device: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"Current GPU Memory Allocated: {torch.cuda.memory_allocated() / 1e9} GB\")\n",
    "print(f\"Current GPU Memory Cached: {torch.cuda.memory_reserved() / 1e9} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0217a72c-db4d-4875-8a00-33f2dae9de5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "from sklearn.model_selection import KFold\n",
    "# 設定參數\n",
    "MAX_LENGTH = 128\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 20\n",
    "\n",
    "# 初始化 BERT 的 tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# 初始化數據\n",
    "messages = df['Inbound Message'].tolist()\n",
    "labels = df['Label'].tolist()\n",
    "\n",
    "# KFold 初始化\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "833a0227-7775-4659-a98c-48c3fbdc9db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, messages, labels, tokenizer, max_length):\n",
    "        self.messages = messages\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.messages)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        message = str(self.messages[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            message,\n",
    "            max_length=self.max_length,\n",
    "            add_special_tokens=True,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "985bf187-a1b5-4882-9e52-2cbc0188e8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義訓練與評估函數\n",
    "def train_epoch(model, dataloader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in tqdm(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dceb8a1-edf1-42fe-ac48-dc84ed4709cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            loss = criterion(logits, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "    \n",
    "    accuracy = correct_predictions.double() / len(dataloader.dataset)\n",
    "    return total_loss / len(dataloader), accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee99c1b8-2fc7-483a-8cb6-d375039c6cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:21<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.9684618836489773 | Val loss: 1.6066787822066613 | Val accuracy: 0.6050119331742244\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:19<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.44244602638281 | Val loss: 1.4014293298406422 | Val accuracy: 0.6396181384248211\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:19<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.1143376033248034 | Val loss: 1.3731268405352 | Val accuracy: 0.6539379474940334\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:20<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.8531525028964221 | Val loss: 1.4201320825882677 | Val accuracy: 0.6599045346062052\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:20<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.644195708240998 | Val loss: 1.4609643156236072 | Val accuracy: 0.6229116945107399\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:19<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.5100190417793722 | Val loss: 1.5433505767921232 | Val accuracy: 0.649164677804296\n",
      "Early stopping triggered at epoch 6\n",
      "Fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:19<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.9742553517601247 | Val loss: 1.6349444085696958 | Val accuracy: 0.6181384248210025\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.459527789915012 | Val loss: 1.4593111062949558 | Val accuracy: 0.6217183770883055\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.1555060867725286 | Val loss: 1.414582686041886 | Val accuracy: 0.6527446300715991\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.8950734835560039 | Val loss: 1.4402786780078456 | Val accuracy: 0.6551312649164678\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.6916218278061409 | Val loss: 1.4958188989252414 | Val accuracy: 0.6563245823389022\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.5314731493402841 | Val loss: 1.5821373271492292 | Val accuracy: 0.6288782816229117\n",
      "Early stopping triggered at epoch 6\n",
      "Fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:19<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.9695514984807725 | Val loss: 1.6699603301174235 | Val accuracy: 0.594272076372315\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.4756728250975326 | Val loss: 1.5143477793009776 | Val accuracy: 0.6085918854415274\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.1502575636920283 | Val loss: 1.4315804704180304 | Val accuracy: 0.649164677804296\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.8971369572425798 | Val loss: 1.46087062415087 | Val accuracy: 0.6408114558472554\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.6717480150193481 | Val loss: 1.5188826994513565 | Val accuracy: 0.6503579952267303\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.5156461417801299 | Val loss: 1.587437224275661 | Val accuracy: 0.6527446300715991\n",
      "Early stopping triggered at epoch 6\n",
      "Fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.9836862865140883 | Val loss: 1.629950371553313 | Val accuracy: 0.5894988066825776\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.483702512742099 | Val loss: 1.4355329173915792 | Val accuracy: 0.6229116945107399\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.1787530099499528 | Val loss: 1.349069855685504 | Val accuracy: 0.6503579952267303\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.905929312709782 | Val loss: 1.4067130347467818 | Val accuracy: 0.6563245823389022\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.6819319546822522 | Val loss: 1.4810608861581334 | Val accuracy: 0.6348448687350836\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.540361968247946 | Val loss: 1.4726181525104451 | Val accuracy: 0.6563245823389022\n",
      "Early stopping triggered at epoch 6\n",
      "Fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.986720365487923 | Val loss: 1.6567273674146183 | Val accuracy: 0.5883054892601433\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.4844833919936318 | Val loss: 1.5319658349145133 | Val accuracy: 0.6193317422434368\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.2277932709430235 | Val loss: 1.446274825986826 | Val accuracy: 0.613365155131265\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.9734150495190742 | Val loss: 1.4137413726662689 | Val accuracy: 0.613365155131265\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7562833770209829 | Val loss: 1.5481858776425415 | Val accuracy: 0.6467780429594272\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.594547966337305 | Val loss: 1.5313587649813238 | Val accuracy: 0.6229116945107399\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.4812797046013934 | Val loss: 1.6609298783653188 | Val accuracy: 0.6420047732696897\n",
      "Early stopping triggered at epoch 7\n",
      "Fold 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.9976675687199932 | Val loss: 1.8340930331428096 | Val accuracy: 0.5644391408114559\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.5258256359878233 | Val loss: 1.58941898255978 | Val accuracy: 0.5871121718377088\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.2041444061166149 | Val loss: 1.4948001762606062 | Val accuracy: 0.6229116945107399\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.9370533030448576 | Val loss: 1.498134711441004 | Val accuracy: 0.6276849642004774\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7122204017083523 | Val loss: 1.5377196872009422 | Val accuracy: 0.616945107398568\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.5437752527453131 | Val loss: 1.5675279959192816 | Val accuracy: 0.630071599045346\n",
      "Early stopping triggered at epoch 6\n",
      "Fold 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.9399234734601893 | Val loss: 1.4968295153581872 | Val accuracy: 0.6276849642004774\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.4697138184713106 | Val loss: 1.4144841578771483 | Val accuracy: 0.6288782816229117\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.1585763915110443 | Val loss: 1.3633243486566364 | Val accuracy: 0.6431980906921241\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.9024665769410588 | Val loss: 1.3750107108422045 | Val accuracy: 0.6384248210023866\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.6979694666056815 | Val loss: 1.3572308668550455 | Val accuracy: 0.6575178997613366\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:19<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.533882397866287 | Val loss: 1.3939152196893152 | Val accuracy: 0.662291169451074\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.4339661336882766 | Val loss: 1.4704520848562133 | Val accuracy: 0.6599045346062052\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.35407408355277475 | Val loss: 1.617097261941658 | Val accuracy: 0.6551312649164678\n",
      "Early stopping triggered at epoch 8\n",
      "Fold 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.9992907503146236 | Val loss: 1.7482929859521255 | Val accuracy: 0.5871121718377088\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.5431400010267557 | Val loss: 1.5232337701995418 | Val accuracy: 0.6217183770883055\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.2572280691336777 | Val loss: 1.4365240920264766 | Val accuracy: 0.6396181384248211\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.9934179958555911 | Val loss: 1.547347144135889 | Val accuracy: 0.6372315035799523\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.8067623854504299 | Val loss: 1.506786120387743 | Val accuracy: 0.6396181384248211\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.6264893585437182 | Val loss: 1.6267741094782668 | Val accuracy: 0.6479713603818616\n",
      "Early stopping triggered at epoch 6\n",
      "Fold 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.9557508168331648 | Val loss: 1.7815079227933344 | Val accuracy: 0.5286396181384249\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.489527616776147 | Val loss: 1.5605523507550079 | Val accuracy: 0.5847255369928401\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.202445075673572 | Val loss: 1.3488499792116992 | Val accuracy: 0.6384248210023866\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.9306567496288631 | Val loss: 1.3175628933141816 | Val accuracy: 0.6599045346062052\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7124215619070298 | Val loss: 1.4329317583228058 | Val accuracy: 0.6563245823389022\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.5341724085353189 | Val loss: 1.5097187785607464 | Val accuracy: 0.6431980906921241\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.4495799266733229 | Val loss: 1.487479492740811 | Val accuracy: 0.6694510739856803\n",
      "Early stopping triggered at epoch 7\n",
      "Fold 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.9657773641332732 | Val loss: 1.6069705722466954 | Val accuracy: 0.6193317422434368\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.489341743479846 | Val loss: 1.4354533316954128 | Val accuracy: 0.6336515513126492\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:19<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.1749951461235346 | Val loss: 1.3831188847433846 | Val accuracy: 0.6587112171837709\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.9051675206618541 | Val loss: 1.3945068806972143 | Val accuracy: 0.6515513126491647\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.6925637411521905 | Val loss: 1.352493039841922 | Val accuracy: 0.6730310262529833\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.5591060591356481 | Val loss: 1.404189462931651 | Val accuracy: 0.6813842482100239\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.4383112332325871 | Val loss: 1.451171434150552 | Val accuracy: 0.662291169451074\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [03:18<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3638418332093506 | Val loss: 1.574734388657336 | Val accuracy: 0.6479713603818616\n",
      "Early stopping triggered at epoch 8\n",
      "10-fold Cross-Validation Results:\n",
      "Average Validation Loss: 1.5720086407830132\n",
      "Average Validation Accuracy: 0.6479713603818615\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# 進行 10 折交叉驗證\n",
    "fold_results = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(messages)):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "\n",
    "    # 折分數據\n",
    "    train_messages = [messages[i] for i in train_idx]\n",
    "    train_labels = [labels[i] for i in train_idx]\n",
    "    val_messages = [messages[i] for i in val_idx]\n",
    "    val_labels = [labels[i] for i in val_idx]\n",
    "\n",
    "    # 建立 Dataset 和 DataLoader\n",
    "    train_dataset = CustomDataset(\n",
    "        messages=train_messages,\n",
    "        labels=train_labels,\n",
    "        tokenizer=tokenizer,\n",
    "        max_length=MAX_LENGTH\n",
    "    )\n",
    "    val_dataset = CustomDataset(\n",
    "        messages=val_messages,\n",
    "        labels=val_labels,\n",
    "        tokenizer=tokenizer,\n",
    "        max_length=MAX_LENGTH\n",
    "    )\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "    # 初始化模型\n",
    "    NUM_LABELS = len(set(labels))\n",
    "    model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=NUM_LABELS, ignore_mismatched_sizes=True)\n",
    "    model.to(device)\n",
    "\n",
    "    # 初始化優化器和損失函數\n",
    "    optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    # Early stopping 參數\n",
    "    patience = 3  # 連續幾個 epoch 沒有提升就停止\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_without_improvement = 0\n",
    "    \n",
    "    # 訓練模型\n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
    "        train_loss = train_epoch(model, train_dataloader, optimizer, criterion)\n",
    "        val_loss, val_accuracy = eval_model(model, val_dataloader, criterion)\n",
    "        print(f\"Train loss: {train_loss} | Val loss: {val_loss} | Val accuracy: {val_accuracy}\")\n",
    "\n",
    "        # Early Stopping 判斷\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_without_improvement = 0  # 重置計數\n",
    "        else:\n",
    "            epochs_without_improvement += 1  # 增加計數\n",
    "        \n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch + 1}\")\n",
    "            break  # 終止訓練\n",
    "\n",
    "    # 保存每折的結果\n",
    "    fold_results.append({\"fold\": fold + 1, \"val_loss\": val_loss, \"val_accuracy\": val_accuracy.item()})\n",
    "\n",
    "# 計算總體平均結果\n",
    "avg_val_loss = np.mean([result[\"val_loss\"] for result in fold_results])\n",
    "avg_val_accuracy = np.mean([result[\"val_accuracy\"] for result in fold_results])\n",
    "\n",
    "print(f\"10-fold Cross-Validation Results:\")\n",
    "print(f\"Average Validation Loss: {avg_val_loss}\")\n",
    "print(f\"Average Validation Accuracy: {avg_val_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8016681-94ee-4d35-81ac-9831d7172f0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
